{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f75bd5ced50>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\n",
    "from Libs.Dataset import Dataset\n",
    "from Libs.Model import Net\n",
    "from Libs.train import train_model, eval_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "# random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_training = \"./data/training_data/training_data\"\n",
    "dir_testing = \"./data//testing_data/testing_data\"\n",
    "csv_file = \"data/training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "label_ids = {}\n",
    "for label in df[\"label\"]:\n",
    "    if label not in label_ids:\n",
    "        label_ids[label] = len(label_ids)\n",
    "id_labels =  {v: k for k, v in label_ids.items()}"
   ]
  },
  {
   "source": [
    "## Dataset preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "005530.jpg\n"
     ]
    }
   ],
   "source": [
    "# data.train = data.load_dir(dir_training)\n",
    "# data.test = data.load_dir(dir_testing)\n",
    "train_trans = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                 transforms.Normalize((0.5), (0.5))])\n",
    "# train_dataset = torchvision.datasets.ImageFolder(root=dir_training, transform=train_trans)\n",
    "train_dataset = Dataset(dir_training, csv_file, label_ids, transform=train_trans)\n",
    "# print(len(train_dataset))\n",
    "train_dataset, test_dataset = train_dataset.train_test_split()\n",
    "print(test_dataset.data[0])\n",
    "# print(len(train_dataset))\n",
    "# print(len(test_dataset))\n",
    "train_loader =  torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True,drop_last=False, num_workers=4)\n",
    "\n",
    "# test_trans = transforms.Compose([transforms.Resize((400, 400)),\n",
    "#                                  transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "#                                  transforms.Normalize((0.5), (0.5))])\n",
    "# test_dataset =  Dataset(dir_testing, csv_file, label_ids=None, transform=train_trans)                               \n",
    "# # test_dataset = torchvision.datasets.ImageFolder(root=dir_training, transform=test_trans)                                 \n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.cuda.device_count():  10\n",
      "Training epoch 1 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 1, duration: 104 s, loss: 0.0387, acc: 0.0375\n",
      "Accuracy of the network on the test images: 13 %\n",
      "Training epoch 2 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 2, duration: 77 s, loss: 0.0275, acc: 0.2137\n",
      "Accuracy of the network on the test images: 34 %\n",
      "Training epoch 3 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 3, duration: 77 s, loss: 0.0180, acc: 0.4722\n",
      "Accuracy of the network on the test images: 54 %\n",
      "Training epoch 4 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 4, duration: 77 s, loss: 0.0115, acc: 0.6754\n",
      "Accuracy of the network on the test images: 67 %\n",
      "Training epoch 5 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 5, duration: 77 s, loss: 0.0071, acc: 0.8080\n",
      "Accuracy of the network on the test images: 78 %\n",
      "Training epoch 6 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 6, duration: 77 s, loss: 0.0048, acc: 0.8761\n",
      "Accuracy of the network on the test images: 82 %\n",
      "Training epoch 7 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 7, duration: 77 s, loss: 0.0033, acc: 0.9168\n",
      "Accuracy of the network on the test images: 84 %\n",
      "Training epoch 8 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 8, duration: 77 s, loss: 0.0024, acc: 0.9392\n",
      "Accuracy of the network on the test images: 87 %\n",
      "Training epoch 9 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 9, duration: 77 s, loss: 0.0016, acc: 0.9684\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 10 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 10, duration: 75 s, loss: 0.0013, acc: 0.9735\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 11 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 11, duration: 75 s, loss: 0.0012, acc: 0.9764\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 12 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 12, duration: 75 s, loss: 0.0012, acc: 0.9762\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 13 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 13, duration: 74 s, loss: 0.0011, acc: 0.9773\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 14 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 14, duration: 74 s, loss: 0.0011, acc: 0.9784\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 15 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 15, duration: 75 s, loss: 0.0011, acc: 0.9783\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 16 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 16, duration: 74 s, loss: 0.0011, acc: 0.9798\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 17 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 17, duration: 74 s, loss: 0.0011, acc: 0.9800\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 18 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 18, duration: 74 s, loss: 0.0011, acc: 0.9792\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 19 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 19, duration: 74 s, loss: 0.0011, acc: 0.9773\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 20 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 20, duration: 74 s, loss: 0.0011, acc: 0.9790\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 21 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 21, duration: 75 s, loss: 0.0011, acc: 0.9800\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 22 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 22, duration: 75 s, loss: 0.0011, acc: 0.9796\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 23 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 23, duration: 75 s, loss: 0.0011, acc: 0.9787\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 24 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 24, duration: 74 s, loss: 0.0011, acc: 0.9789\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 25 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 25, duration: 74 s, loss: 0.0011, acc: 0.9776\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 26 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 26, duration: 74 s, loss: 0.0011, acc: 0.9777\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Training epoch 27 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 27, duration: 75 s, loss: 0.0011, acc: 0.9800\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 28 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 28, duration: 74 s, loss: 0.0011, acc: 0.9780\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 29 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 29, duration: 72 s, loss: 0.0011, acc: 0.9781\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Training epoch 30 ...\n",
      "0\n",
      "30\n",
      "60\n",
      "Epoch 30, duration: 73 s, loss: 0.0011, acc: 0.9776\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "TRAIN_EPOCH_LOAD = 0\n",
    "MODEL_DIR = \"./model/\"\n",
    "end_epoch = 30\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
    "\n",
    "\n",
    "if TRAIN_EPOCH_LOAD <= 0 :\n",
    "    start_epoch = 0\n",
    "else:\n",
    "    start_epoch = TRAIN_EPOCH_LOAD\n",
    "    checkpoint = torch.load('{}.pth'.format(os.path.join(MODEL_DIR, str(TRAIN_EPOCH_LOAD))))\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "    lrscheduler = checkpoint[\"scheduler\"]\n",
    "\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model, training_losses, training_accs, test_accs = train_model(model, train_loader, test_loader, criterion, optimizer, lrscheduler, start_epoch, end_epoch)\n"
   ]
  },
  {
   "source": [
    "## Predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the test images: 91 %\n",
      "Test accuracy of epoch 10: 91.77837354781055\n",
      "0\n",
      "30\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "predict = {}\n",
    "load_epoch = 10\n",
    "\n",
    "model.load_state_dict(torch.load('{}.pth'.format(os.path.join(\"./model/\", str(load_epoch))))[\"model\"])\n",
    "model.eval()\n",
    "print(\"Test accuracy of epoch {}: {}\".format(load_epoch, eval_model(model, test_loader)))\n",
    "\n",
    "eval_trans = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                 transforms.Normalize((0.5), (0.5))])\n",
    "eval_dataset =  Dataset(dir_testing, csv_file, label_ids=None, transform=eval_trans, eval=True)\n",
    "eval_loader =  torch.utils.data.DataLoader(eval_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, inputs in enumerate(eval_loader):\n",
    "        if b%30 == 0:\n",
    "            print(b)\n",
    "\n",
    "        imgs, img_names = inputs\n",
    "        imgs = imgs.to(device)\n",
    "        output = model(imgs)\n",
    "        p = torch.argmax(output, 1)\n",
    "        for i, img_name in enumerate(img_names):\n",
    "            predict[img_name] = id_labels[p[i].item()]\n",
    "    # print(predict)\n",
    "\n",
    "with open('submission.csv', 'w',newline='') as csvfile:\n",
    "    fieldnames=[\"id\", \"label\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for key, value in predict.items():\n",
    "        writer.writerow({fieldnames[0]: key, fieldnames[1]: value})\n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}