{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa18e589dd0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "\n",
    "from Libs.Dataset import Dataset\n",
    "from Libs.Model import Net\n",
    "from Libs.train import train_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import csv\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_training = \"./data/training_data/training_data\"\n",
    "dir_testing = \"./data//testing_data/testing_data\"\n",
    "csv_file = \"data/training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "label_ids = {}\n",
    "for label in df[\"label\"]:\n",
    "    if label not in label_ids:\n",
    "        label_ids[label] = len(label_ids)\n",
    "id_labels =  {v: k for k, v in label_ids.items()}"
   ]
  },
  {
   "source": [
    "## Dataset preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.train = data.load_dir(dir_training)\n",
    "# data.test = data.load_dir(dir_testing)\n",
    "train_trans = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                 transforms.Normalize((0.5), (0.5))])\n",
    "# train_dataset = torchvision.datasets.ImageFolder(root=dir_training, transform=train_trans)\n",
    "train_dataset = Dataset(dir_training, csv_file, label_ids, transform=train_trans)\n",
    "train_loader =  torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True,drop_last=True)\n",
    "test_trans = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                 transforms.Normalize((0.5), (0.5))])\n",
    "test_dataset =  Dataset(dir_testing, csv_file, label_ids=None, transform=test_trans)                               \n",
    "# test_dataset = torchvision.datasets.ImageFolder(root=dir_training, transform=test_trans)                                 \n",
    "test_loader =  torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training epoch 1 ...\n",
      "Epoch 1, duration: 2 s, loss: 0.2236, acc: 0.8200\n",
      "Training epoch 2 ...\n",
      "Epoch 2, duration: 2 s, loss: 0.3503, acc: 0.7100\n",
      "Training epoch 3 ...\n",
      "Epoch 3, duration: 2 s, loss: 0.2041, acc: 0.6800\n",
      "Training epoch 4 ...\n",
      "Epoch 4, duration: 2 s, loss: 0.1200, acc: 0.7900\n",
      "Training epoch 5 ...\n",
      "Epoch 5, duration: 2 s, loss: 0.0912, acc: 0.8400\n",
      "Training epoch 6 ...\n",
      "Epoch 6, duration: 2 s, loss: 0.1005, acc: 0.8300\n",
      "Training epoch 7 ...\n",
      "Epoch 7, duration: 2 s, loss: 0.0736, acc: 0.9000\n",
      "Training epoch 8 ...\n",
      "Epoch 8, duration: 2 s, loss: 0.0859, acc: 0.8800\n",
      "Training epoch 9 ...\n",
      "Epoch 9, duration: 2 s, loss: 0.0560, acc: 0.9400\n",
      "Training epoch 10 ...\n",
      "Epoch 10, duration: 2 s, loss: 0.0781, acc: 0.8900\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(model.device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "import traceback\n",
    "\n",
    "model, training_losses, training_accs, test_accs = train_model(model, train_loader, test_loader, criterion, optimizer, lrscheduler, 10)\n"
   ]
  },
  {
   "source": [
    "## Predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "predict = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for inputs in test_loader:\n",
    "        imgs, img_names = inputs\n",
    "        imgs = imgs.to(model.device)\n",
    "        p = model.predict(imgs)\n",
    "        for i, img_name in enumerate(img_names):\n",
    "            predict[img_name] = id_labels[p[i].item()]\n",
    "    # print(predict)\n",
    "\n",
    "with open('submission.csv', 'w',newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"id\", \"labels\"])\n",
    "    writer.writeheader()\n",
    "    for key, value in predict.items():\n",
    "        writer.writerow({'id': key, 'labels': value})\n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}